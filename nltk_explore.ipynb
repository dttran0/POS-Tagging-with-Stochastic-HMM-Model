{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import brown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry. The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066. Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace. Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry. The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066. Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace. Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Millions of people across the UK and beyond have celebrated the coronation of King Charles III - a symbolic ceremony combining a religious service and pageantry.',\n",
       " 'The ceremony was held at Westminster Abbey, with the King becoming the 40th reigning monarch to be crowned there since 1066.',\n",
       " 'Queen Camilla was crowned alongside him before a huge parade back to Buckingham Palace.',\n",
       " \"Here's how the day of splendour and formality, which featured customs dating back more than 1,000 years, unfolded.\"]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Millions', 'of', 'people', 'across', 'the', 'UK', 'and', 'beyond', 'have', 'celebrated', 'the', 'coronation', 'of', 'King', 'Charles', 'III', '-', 'a', 'symbolic', 'ceremony', 'combining', 'a', 'religious', 'service', 'and', 'pageantry', '.']\n"
     ]
    }
   ],
   "source": [
    "#tokenize the sentence in each separate word \n",
    "words = word_tokenize(sentences[0])\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#check out possible stop word in English\n",
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Millions', 'NNS'),\n",
       " ('people', 'NNS'),\n",
       " ('across', 'IN'),\n",
       " ('UK', 'NNP'),\n",
       " ('beyond', 'IN'),\n",
       " ('celebrated', 'VBN'),\n",
       " ('coronation', 'NN'),\n",
       " ('King', 'NNP'),\n",
       " ('Charles', 'NNP'),\n",
       " ('III', 'NNP'),\n",
       " ('symbolic', 'JJ'),\n",
       " ('ceremony', 'NN'),\n",
       " ('combining', 'VBG'),\n",
       " ('religious', 'JJ'),\n",
       " ('service', 'NN'),\n",
       " ('pageantry', 'NN')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out the stop word\n",
    "\n",
    "# Remove stop words\n",
    "words = [w for w in words if w not in stopwords.words(\"english\") and w not in string.punctuation]\n",
    "token_tag = pos_tag(words)\n",
    "\n",
    "token_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate in HMM model for POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import hmm\n",
    "from nltk.corpus import treebank, brown, conll2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter punctuation from tagged sentences\n",
    "def filter_punctuation(tagged_sentences):\n",
    "    filtered_sentences = []\n",
    "    for sentence in tagged_sentences:\n",
    "        filtered_sentence = [(word, tag) for word, tag in sentence if word not in string.punctuation]\n",
    "        if filtered_sentence:  # Only add non-empty sentences\n",
    "            filtered_sentences.append(filtered_sentence)\n",
    "        filtered_sentences.append(filtered_sentence)\n",
    "    return filtered_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the HMM model on the test data\n",
    "def evaluate_hmm_tagger(test_data, hmm_tagger):\n",
    "    \n",
    "    words_list = []\n",
    "    predicted_tags_list = []\n",
    "    gold_tag_list = []\n",
    "    correct = total = 0\n",
    "    for sentence in test_data:\n",
    "        #print(sentence)\n",
    "        words, gold_tags = zip(*sentence)\n",
    "        words = [word.lower() for word in words if word not in string.punctuation]\n",
    "        predicted_tags = [tag for word, tag in hmm_tagger.tag(words)]\n",
    "        correct += sum(p == g for p, g in zip(predicted_tags, gold_tags))\n",
    "        total += len(gold_tags)\n",
    "\n",
    "        words_list.append(' '.join(words))\n",
    "        predicted_tags_list.append(predicted_tags)\n",
    "        gold_tag_list.append(gold_tags)\n",
    "       \n",
    "    #showing the first 5 performance \n",
    "    for i in range(5):\n",
    "        print(f\"Sentence: {words_list[i]}\")\n",
    "        print(f\"Predicted tags: {predicted_tags_list[i]}\")\n",
    "        print(f\"Actual tags:    {gold_tag_list[i]}\")\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_corpus(corpus_name, tagged_sentences):\n",
    "    print(f\"\\n--- Evaluating {corpus_name} Corpus ---\\n\")\n",
    "    # Filter out punctuation\n",
    "    tagged_sentences = filter_punctuation(tagged_sentences)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    train_size = int(len(tagged_sentences) * 0.8)\n",
    "    train_data = tagged_sentences[:train_size]\n",
    "    test_data = tagged_sentences[train_size:]\n",
    "    \n",
    "    train_data = [s for s in train_data if s]\n",
    "    test_data = [s for s in test_data if s]\n",
    "    \n",
    "    # Train the HMM POS tagger\n",
    "    trainer = hmm.HiddenMarkovModelTrainer()\n",
    "    hmm_tagger = trainer.train(train_data)\n",
    "    \n",
    "    # Evaluate the HMM model on the test data\n",
    "    accuracy = evaluate_hmm_tagger(test_data, hmm_tagger)\n",
    "    print(f'{corpus_name} Corpus Accuracy: {accuracy:.4f}')\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Treebank Corpus ---\n",
      "\n",
      "Sentence: the latest 10-year notes were quoted at 100 22\\/32 *-1 to yield 7.88 compared with 100 16\\/32 to yield 7.90\n",
      "Predicted tags: ['DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NUM', 'PRT', 'VERB', 'NUM')\n",
      "Sentence: the latest 10-year notes were quoted at 100 22\\/32 *-1 to yield 7.88 compared with 100 16\\/32 to yield 7.90\n",
      "Predicted tags: ['DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NUM', 'PRT', 'VERB', 'NUM')\n",
      "Sentence: the discount rate on three-month treasury bills was essentially unchanged at 7.79 while the rate on six-month bills was slightly lower at 7.52 compared with 7.60 tuesday\n",
      "Predicted tags: ['DET', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN')\n",
      "Sentence: the discount rate on three-month treasury bills was essentially unchanged at 7.79 while the rate on six-month bills was slightly lower at 7.52 compared with 7.60 tuesday\n",
      "Predicted tags: ['DET', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN')\n",
      "Sentence: corporate issues\n",
      "Predicted tags: ['ADJ', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN')\n",
      "Treebank Corpus Accuracy: 0.4651\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_treebank = treebank.tagged_sents(tagset='universal')\n",
    "train_and_evaluate_corpus('Treebank', tagged_sentences_treebank)\n",
    "\n",
    "# tagged_sentences_brown = brown.tagged_sents(tagset='universal')\n",
    "# train_and_evaluate_corpus('Brown', tagged_sentences_brown)\n",
    "\n",
    "# Conll2000 Corpus\n",
    "# tagged_sentences_conll2000 = conll2000.tagged_sents(tagset='universal')\n",
    "# train_and_evaluate_corpus('Conll2000', tagged_sentences_conll2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Brown Corpus ---\n",
      "\n",
      "Sentence: i know as well as the next man that a ship is called from the rigging she carries where the live wind blows and not from the hull\n",
      "Predicted tags: ['NOUN', 'VERB', 'ADV', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'VERB', 'PRON', 'VERB', 'ADV', 'DET', 'ADJ', 'NOUN', 'VERB', 'CONJ', 'ADV', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('PRON', 'VERB', 'ADV', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'ADV', 'DET', 'ADJ', 'NOUN', 'VERB', 'CONJ', 'ADV', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: i know as well as the next man that a ship is called from the rigging she carries where the live wind blows and not from the hull\n",
      "Predicted tags: ['NOUN', 'VERB', 'ADV', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'VERB', 'PRON', 'VERB', 'ADV', 'DET', 'ADJ', 'NOUN', 'VERB', 'CONJ', 'ADV', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('PRON', 'VERB', 'ADV', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'PRON', 'VERB', 'ADV', 'DET', 'ADJ', 'NOUN', 'VERB', 'CONJ', 'ADV', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: but you've got to know both\n",
      "Predicted tags: ['CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET']\n",
      "Actual tags:    ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET')\n",
      "Sentence: but you've got to know both\n",
      "Predicted tags: ['CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET']\n",
      "Actual tags:    ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET')\n",
      "Sentence: what's below the water-line interests me also\n",
      "Predicted tags: ['PRT', 'ADP', 'DET', 'DET', 'DET', 'DET', 'DET']\n",
      "Actual tags:    ('PRT', 'ADP', 'DET', 'NOUN', 'VERB', 'PRON', 'ADV')\n",
      "Brown Corpus Accuracy: 0.6078\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_brown = brown.tagged_sents(tagset='universal')\n",
    "train_and_evaluate_corpus('Brown', tagged_sentences_brown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Conll2000 Corpus ---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trand\\anaconda3\\envs\\cs_178\\lib\\site-packages\\nltk\\tag\\hmm.py:334: RuntimeWarning: overflow encountered in cast\n",
      "  X[i, j] = self._transitions[si].logprob(self._states[j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the debentures were issued in the face amount of 46 million on july 11 1988 the ashland ky. coal mining water transportation and construction company said\n",
      "Predicted tags: ['DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'NUM', 'NUM', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'NUM', 'NUM', 'ADP', 'NOUN', 'NUM', 'NUM', 'DET', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'VERB')\n",
      "Sentence: the company said the redemption is permitted because the price of addington 's stock has equaled or exceeded 19.60 for 20 consecutive trading days a condition set in the terms of the debentures\n",
      "Predicted tags: ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'CONJ', 'VERB', 'NUM', 'ADP', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: the company said the redemption is permitted because the price of addington 's stock has equaled or exceeded 19.60 for 20 consecutive trading days a condition set in the terms of the debentures\n",
      "Predicted tags: ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'CONJ', 'VERB', 'NUM', 'ADP', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: debenture holders are expected to convert most of the debentures into common because the value of the stock received in a conversion would exceed the 1,103.11 redemption price\n",
      "Predicted tags: ['NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NUM', 'NOUN', 'NOUN')\n",
      "Sentence: debenture holders are expected to convert most of the debentures into common because the value of the stock received in a conversion would exceed the 1,103.11 redemption price\n",
      "Predicted tags: ['NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NUM', 'NOUN', 'NOUN')\n",
      "Conll2000 Corpus Accuracy: 0.5453\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_conll2000 = conll2000.tagged_sents(tagset='universal')\n",
    "train_and_evaluate_corpus('Conll2000', tagged_sentences_conll2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
