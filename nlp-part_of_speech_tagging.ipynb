{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import treebank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HMM + Viterbi for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get each sentence and tokenize as word \n",
    "# tokenized_sentences = []\n",
    "# for sentence in sentences:\n",
    "#     words = word_tokenize(sentence)\n",
    "#     words = [word for word in words if word not in string.punctuation]\n",
    "#     tokenized_sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_punctuation(tagged_sentences):\n",
    "    filtered_sentences = []\n",
    "    for sentence in tagged_sentences:\n",
    "        filtered_sentence = [(word, tag) for word, tag in sentence if word not in string.punctuation]\n",
    "        if filtered_sentence:  # Only add non-empty sentences\n",
    "            filtered_sentences.append(filtered_sentence)\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(tagged_sentences):\n",
    "    \n",
    "    tagged_sentences = filter_punctuation(tagged_sentences)\n",
    "    \n",
    "    train_size = int(0.8 * len(tagged_sentences))  # 80% train, 20% test\n",
    "    train_data = tagged_sentences[:train_size]\n",
    "    test_data = tagged_sentences[train_size:]\n",
    "    train_data = [s for s in train_data if s]\n",
    "    test_data = [s for s in test_data if s]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emissions_transitions(train_data):\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    for sentence in train_data:\n",
    "        previous_tag = '<s>'\n",
    "        for word, tag in sentence:\n",
    "            emission_counts[tag][word.lower()] += 1\n",
    "            transition_counts[previous_tag][tag] += 1\n",
    "            tag_counts[tag] += 1\n",
    "            previous_tag = tag\n",
    "        transition_counts[previous_tag]['</s>'] += 1\n",
    "    \n",
    "    return emission_counts, transition_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(emission_counts, transition_counts, tag_counts):\n",
    "    emission_prob = defaultdict(lambda: defaultdict(float))\n",
    "    for tag, words in emission_counts.items():\n",
    "        total_count = float(tag_counts[tag])\n",
    "        for word, count in words.items():\n",
    "            emission_prob[tag][word] = count / total_count\n",
    "\n",
    "    transition_prob = defaultdict(lambda: defaultdict(float))\n",
    "    for prev_tag, next_tags in transition_counts.items():\n",
    "        total_count = float(sum(next_tags.values()))\n",
    "        for next_tag, count in next_tags.items():\n",
    "            transition_prob[prev_tag][next_tag] = count / total_count\n",
    "\n",
    "    return emission_prob, transition_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the treebank corpus\n",
    "# tagged_sentences = treebank.tagged_sents(tagset='universal')\n",
    "# tagged_sentences = filter_punctuation(tagged_sentences)\n",
    "\n",
    "# Split into training and testing data\n",
    "# train_data = tagged_sentences[:3000]\n",
    "# test_data = tagged_sentences[3000:]\n",
    "\n",
    "# # Create dictionaries to hold emission and transition probabilities\n",
    "# emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "# transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "# tag_counts = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count emissions and transitions\n",
    "# for sentence in train_data:\n",
    "#     previous_tag = '<s>'\n",
    "#     for word, tag in sentence:\n",
    "#         emission_counts[tag][word.lower()] += 1\n",
    "#         transition_counts[previous_tag][tag] += 1\n",
    "#         tag_counts[tag] += 1\n",
    "#         previous_tag = tag\n",
    "#     transition_counts[previous_tag]['</s>'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emission probabilities: for the observable states\n",
    "# emission_prob = defaultdict(lambda: defaultdict(float))\n",
    "# for tag, words in emission_counts.items():\n",
    "#     total_count = float(tag_counts[tag])\n",
    "#     for word, count in words.items():\n",
    "#         emission_prob[tag][word] = count / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate transition probabilities: a dictionary that tells the probability of getting a particular tag as \n",
    "#the next POS tag given that which tag had occured previously.\n",
    "# transition_prob = defaultdict(lambda: defaultdict(float))\n",
    "# for prev_tag, next_tags in transition_counts.items():\n",
    "#     total_count = float(sum(next_tags.values()))\n",
    "#     for next_tag, count in next_tags.items():\n",
    "#         transition_prob[prev_tag][next_tag] = count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in emission_prob.items():\n",
    "#     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi algorithm\n",
    "def viterbi(observation_seqs, transition_prob, emission_prob, tag_counts):\n",
    "    states = list(tag_counts.keys())\n",
    "    num_states = len(states)\n",
    "    num_obs = len(observation_seqs)\n",
    "    \n",
    "    # Initialize the probability matrix and the backpointer matrix\n",
    "    prob_matrix = np.zeros((num_states, num_obs))\n",
    "    backtrack = np.zeros((num_states, num_obs), dtype=int)\n",
    "    \n",
    "    # Initial probabilities\n",
    "    initial_states = np.array([transition_prob['<s>'][state] for state in states])\n",
    "    \n",
    "    # Populate the initial column of the probability matrix\n",
    "    for state_index, state in enumerate(states):\n",
    "        prob_matrix[state_index, 0] = initial_states[state_index] * emission_prob[state].get(observation_seqs[0], 1e-6)\n",
    "    \n",
    "    # Populate the probability matrix for t > 0\n",
    "    for t in range(1, num_obs):\n",
    "        for state_index, state in enumerate(states):\n",
    "            max_prob, max_state = max(\n",
    "                (prob_matrix[prev_state_index, t-1] * transition_prob[prev_state][state] * emission_prob[state].get(observation_seqs[t], 1e-6), prev_state_index)\n",
    "                for prev_state_index, prev_state in enumerate(states)\n",
    "            )\n",
    "            prob_matrix[state_index, t] = max_prob\n",
    "            backtrack[state_index, t] = max_state\n",
    "    \n",
    "    # Find the most probable state sequence\n",
    "    optimal_path = np.zeros(num_obs, dtype=int)\n",
    "    optimal_path[-1] = np.argmax(prob_matrix[:, -1])\n",
    "    \n",
    "    for t in range(num_obs - 2, -1, -1):\n",
    "        optimal_path[t] = backtrack[optimal_path[t + 1], t + 1]\n",
    "    \n",
    "    # Convert indices back to state names\n",
    "    optimal_tags = [states[state_index] for state_index in optimal_path]\n",
    "    \n",
    "    return optimal_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "\n",
    "def evaluate_hmm(test_data, transition_prob, emission_prob, tag_counts):\n",
    "    words_list = []\n",
    "    predicted_tags_list = []\n",
    "    gold_tag_list = []\n",
    "    correct = total = 0\n",
    "    for sentence in test_data:\n",
    "        words, gold_tags = zip(*sentence)\n",
    "        words = [word.lower() for word in words]\n",
    "        predicted_tags = viterbi(words, transition_prob, emission_prob, tag_counts)\n",
    "        correct += sum(p == g for p, g in zip(predicted_tags, gold_tags))\n",
    "        total += len(gold_tags)\n",
    "        # Print the comparison for each sentence\n",
    "        words_list.append(' '.join(words))\n",
    "        predicted_tags_list.append(predicted_tags)\n",
    "        gold_tag_list.append(gold_tags)\n",
    "        # print(f\"Sentence: {' '.join(words)}\")\n",
    "        # print(f\"Predicted tags: {predicted_tags}\")\n",
    "        # print(f\"Actual tags:    {gold_tags}\")\n",
    "        # print()\n",
    "    #showing the first 5 performance \n",
    "    for i in range(5):\n",
    "        print(f\"Sentence: {words_list[i]}\")\n",
    "        print(f\"Predicted tags: {predicted_tags_list[i]}\")\n",
    "        print(f\"Actual tags:    {gold_tag_list[i]}\")\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(corpus_name, tag_sentence):\n",
    "    train_data, test_data = prepare_data(tag_sentence)\n",
    "    emission_counts, transition_counts, tag_counts = count_emissions_transitions(train_data)\n",
    "    emission_prob, transition_prob = calculate_probabilities(emission_counts, transition_counts, tag_counts)\n",
    "    accuracy = evaluate_hmm(test_data, transition_prob, emission_prob, tag_counts)\n",
    "    print(f'{corpus_name} Corpus Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the latest 10-year notes were quoted at 100 22\\/32 *-1 to yield 7.88 compared with 100 16\\/32 to yield 7.90\n",
      "Predicted tags: ['DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'X', 'PRT', 'VERB', 'NUM']\n",
      "Actual tags:    ('DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NUM', 'PRT', 'VERB', 'NUM')\n",
      "Sentence: the discount rate on three-month treasury bills was essentially unchanged at 7.79 while the rate on six-month bills was slightly lower at 7.52 compared with 7.60 tuesday\n",
      "Predicted tags: ['DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN')\n",
      "Sentence: corporate issues\n",
      "Predicted tags: ['ADJ', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN')\n",
      "Sentence: ibm 's 750 million *u* debenture offering dominated activity in the corporate debt market\n",
      "Predicted tags: ['NOUN', 'PRT', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'PRT', 'NUM', 'NUM', 'X', 'NOUN', 'NOUN', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN')\n",
      "Sentence: meanwhile most investment-grade bonds ended unchanged to as much as 1\\/8 point higher\n",
      "Predicted tags: ['ADV', 'ADV', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'PRT', 'ADP', 'ADJ', 'ADP', 'NUM', 'NOUN', 'ADJ']\n",
      "Actual tags:    ('ADV', 'ADV', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'PRT', 'ADV', 'ADJ', 'ADP', 'NUM', 'NOUN', 'ADJ')\n",
      "Treebank Corpus Accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences = treebank.tagged_sents(tagset='universal')\n",
    "train_and_evaluate('Treebank', tagged_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs_178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
