{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from nltk import pos_tag\n",
    "from nltk.tag import hmm\n",
    "from nltk.corpus import treebank, brown, conll2000, reuters\n",
    "\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\trand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('brown')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('reuters')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM + Viterbi for Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_punctuation(tagged_sentences):\n",
    "    filtered_sentences = []\n",
    "    for sentence in tagged_sentences:\n",
    "        filtered_sentence = [(word, tag) for word, tag in sentence if word not in string.punctuation]\n",
    "        if filtered_sentence:  # Only add non-empty sentences\n",
    "            filtered_sentences.append(filtered_sentence)\n",
    "    return filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(tagged_sentences):\n",
    "    \n",
    "    tagged_sentences = filter_punctuation(tagged_sentences)\n",
    "    \n",
    "    train_size = int(0.8 * len(tagged_sentences))  # 80% train, 20% test\n",
    "    train_data = tagged_sentences[:train_size]\n",
    "    test_data = tagged_sentences[train_size:]\n",
    "    train_data = [s for s in train_data if s]\n",
    "    test_data = [s for s in test_data if s]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emissions_transitions(train_data):\n",
    "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    for sentence in train_data:\n",
    "        previous_tag = '<s>'\n",
    "        for word, tag in sentence:\n",
    "            emission_counts[tag][word.lower()] += 1\n",
    "            transition_counts[previous_tag][tag] += 1\n",
    "            tag_counts[tag] += 1\n",
    "            previous_tag = tag\n",
    "        transition_counts[previous_tag]['</s>'] += 1\n",
    "    \n",
    "    return emission_counts, transition_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(emission_counts, transition_counts, tag_counts):\n",
    "    emission_prob = defaultdict(lambda: defaultdict(float))\n",
    "    for tag, words in emission_counts.items():\n",
    "        total_count = float(tag_counts[tag])\n",
    "        for word, count in words.items():\n",
    "            emission_prob[tag][word] = count / total_count\n",
    "\n",
    "    transition_prob = defaultdict(lambda: defaultdict(float))\n",
    "    for prev_tag, next_tags in transition_counts.items():\n",
    "        total_count = float(sum(next_tags.values()))\n",
    "        for next_tag, count in next_tags.items():\n",
    "            transition_prob[prev_tag][next_tag] = count / total_count\n",
    "\n",
    "    return emission_prob, transition_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi algorithm\n",
    "def viterbi(observation_seqs, transition_prob, emission_prob, tag_counts):\n",
    "    states = list(tag_counts.keys())\n",
    "    num_states = len(states)\n",
    "    num_obs = len(observation_seqs)\n",
    "    \n",
    "    # Initialize the probability matrix and the backpointer matrix\n",
    "    prob_matrix = np.zeros((num_states, num_obs))\n",
    "    backtrack = np.zeros((num_states, num_obs), dtype=int)\n",
    "    \n",
    "    # Initial probabilities\n",
    "    initial_states = np.array([transition_prob['<s>'][state] for state in states])\n",
    "    \n",
    "    # Populate the initial column of the probability matrix\n",
    "    for state_index, state in enumerate(states):\n",
    "        prob_matrix[state_index, 0] = initial_states[state_index] * emission_prob[state].get(observation_seqs[0], 1e-6)\n",
    "    \n",
    "    # Populate the probability matrix for t > 0\n",
    "    for t in range(1, num_obs):\n",
    "        for state_index, state in enumerate(states):\n",
    "            max_prob, max_state = max(\n",
    "                (prob_matrix[prev_state_index, t-1] * transition_prob[prev_state][state] * emission_prob[state].get(observation_seqs[t], 1e-6), prev_state_index)\n",
    "                for prev_state_index, prev_state in enumerate(states)\n",
    "            )\n",
    "            prob_matrix[state_index, t] = max_prob\n",
    "            backtrack[state_index, t] = max_state\n",
    "    \n",
    "    # Find the most probable state sequence\n",
    "    optimal_path = np.zeros(num_obs, dtype=int)\n",
    "    optimal_path[-1] = np.argmax(prob_matrix[:, -1])\n",
    "    \n",
    "    for t in range(num_obs - 2, -1, -1):\n",
    "        optimal_path[t] = backtrack[optimal_path[t + 1], t + 1]\n",
    "    \n",
    "    # Convert indices back to state names\n",
    "    optimal_tags = [states[state_index] for state_index in optimal_path]\n",
    "    \n",
    "    return optimal_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "# With Viterbi\n",
    "def evaluate_hmm(test_data, transition_prob, emission_prob, tag_counts, record_dict):\n",
    "    words_list = []\n",
    "    predicted_tags_list = []\n",
    "    gold_tag_list = []\n",
    "    correct = total = 0\n",
    "    for sentence in test_data:\n",
    "        words, gold_tags = zip(*sentence)\n",
    "        words = [word.lower() for word in words]\n",
    "        predicted_tags = viterbi(words, transition_prob, emission_prob, tag_counts)\n",
    "        correct += sum(p == g for p, g in zip(predicted_tags, gold_tags))\n",
    "        total += len(gold_tags)\n",
    "\n",
    "        for g, p in zip(gold_tags, predicted_tags):\n",
    "            if g != p:\n",
    "                record_dict[g][p] += 1\n",
    "        # Print the comparison for each sentence\n",
    "        words_list.append(' '.join(words))\n",
    "        predicted_tags_list.append(predicted_tags)\n",
    "        gold_tag_list.append(gold_tags)\n",
    "        # print(f\"Sentence: {' '.join(words)}\")\n",
    "        # print(f\"Predicted tags: {predicted_tags}\")\n",
    "        # print(f\"Actual tags:    {gold_tags}\")\n",
    "        # print()\n",
    "    #showing the first 5 performance \n",
    "    for i in range(5):\n",
    "        print(f\"Sentence: {words_list[i]}\")\n",
    "        print(f\"Predicted tags: {predicted_tags_list[i]}\")\n",
    "        print(f\"Actual tags:    {gold_tag_list[i]}\")\n",
    "    return correct / total, gold_tag_list, predicted_tags_list, record_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(corpus_name, tag_sentence, mispredict_dict):\n",
    "    train_data, test_data = prepare_data(tag_sentence)\n",
    "    emission_counts, transition_counts, tag_counts = count_emissions_transitions(train_data)\n",
    "    emission_prob, transition_prob = calculate_probabilities(emission_counts, transition_counts, tag_counts)\n",
    "    accuracy, _ ,_ , miscount_dict  = evaluate_hmm(test_data, transition_prob, emission_prob, tag_counts, mispredict_dict)\n",
    "    print(f'{corpus_name} Corpus Accuracy: {accuracy:.4f}')\n",
    "    return miscount_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_count = defaultdict(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the latest 10-year notes were quoted at 100 22\\/32 *-1 to yield 7.88 compared with 100 16\\/32 to yield 7.90\n",
      "Predicted tags: ['DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'X', 'PRT', 'VERB', 'NUM']\n",
      "Actual tags:    ('DET', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'NUM', 'VERB', 'ADP', 'NUM', 'NUM', 'PRT', 'VERB', 'NUM')\n",
      "Sentence: the discount rate on three-month treasury bills was essentially unchanged at 7.79 while the rate on six-month bills was slightly lower at 7.52 compared with 7.60 tuesday\n",
      "Predicted tags: ['DET', 'NOUN', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'VERB', 'ADV', 'ADJ', 'ADP', 'NUM', 'VERB', 'ADP', 'NUM', 'NOUN')\n",
      "Sentence: corporate issues\n",
      "Predicted tags: ['ADJ', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN')\n",
      "Sentence: ibm 's 750 million *u* debenture offering dominated activity in the corporate debt market\n",
      "Predicted tags: ['NOUN', 'PRT', 'NUM', 'NUM', 'X', 'PRT', 'VERB', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'PRT', 'NUM', 'NUM', 'X', 'NOUN', 'NOUN', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN')\n",
      "Sentence: meanwhile most investment-grade bonds ended unchanged to as much as 1\\/8 point higher\n",
      "Predicted tags: ['ADV', 'ADV', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'PRT', 'ADP', 'ADJ', 'ADP', 'NUM', 'NOUN', 'ADJ']\n",
      "Actual tags:    ('ADV', 'ADV', 'ADJ', 'NOUN', 'VERB', 'ADJ', 'PRT', 'ADV', 'ADJ', 'ADP', 'NUM', 'NOUN', 'ADJ')\n",
      "Treebank Corpus Accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_treebank = treebank.tagged_sents(tagset='universal')\n",
    "misclassification_count = train_and_evaluate('Treebank', tagged_sentences_treebank, misclassification_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: he was courteous and casual about it as though it were of no consequence\n",
      "Predicted tags: ['PRON', 'VERB', 'ADJ', 'CONJ', 'ADJ', 'ADP', 'PRON', 'ADV', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('PRON', 'VERB', 'ADJ', 'CONJ', 'ADJ', 'ADP', 'PRON', 'ADP', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: he's always like that in spite of being a big man\n",
      "Predicted tags: ['PRT', 'ADV', 'ADP', 'PRON', 'ADP', 'NOUN', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN']\n",
      "Actual tags:    ('PRT', 'ADV', 'ADP', 'DET', 'ADP', 'ADP', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN')\n",
      "Sentence: when you see him you'll notice his habit of fingering i might almost say stroking a large mole with black hairs on it by his right temple\n",
      "Predicted tags: ['ADV', 'PRON', 'VERB', 'PRON', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'PRON', 'VERB', 'ADV', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'PRON', 'ADP', 'DET', 'ADJ', 'NOUN']\n",
      "Actual tags:    ('ADV', 'PRON', 'VERB', 'PRON', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'VERB', 'PRON', 'VERB', 'ADV', 'VERB', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'PRON', 'ADP', 'DET', 'ADJ', 'NOUN')\n",
      "Sentence: a sensual man but very courteous some would say slick\n",
      "Predicted tags: ['DET', 'ADJ', 'NOUN', 'CONJ', 'ADV', 'ADP', 'DET', 'VERB', 'VERB', 'ADJ']\n",
      "Actual tags:    ('DET', 'ADJ', 'NOUN', 'CONJ', 'ADV', 'ADJ', 'DET', 'VERB', 'VERB', 'ADJ')\n",
      "Sentence: like his glossy black hair\n",
      "Predicted tags: ['ADP', 'DET', 'ADJ', 'ADJ', 'NOUN']\n",
      "Actual tags:    ('ADP', 'DET', 'ADJ', 'ADJ', 'NOUN')\n",
      "Brown Corpus Accuracy: 0.9340\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_brown = brown.tagged_sents(tagset='universal')\n",
    "misclassification_count = train_and_evaluate('Brown', tagged_sentences_brown, misclassification_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the debentures were issued in the face amount of 46 million on july 11 1988 the ashland ky. coal mining water transportation and construction company said\n",
      "Predicted tags: ['DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'NUM', 'NUM', 'ADP', 'NOUN', 'NUM', 'NUM', 'DET', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'VERB']\n",
      "Actual tags:    ('DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'NUM', 'NUM', 'ADP', 'NOUN', 'NUM', 'NUM', 'DET', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'VERB')\n",
      "Sentence: the company said the redemption is permitted because the price of addington 's stock has equaled or exceeded 19.60 for 20 consecutive trading days a condition set in the terms of the debentures\n",
      "Predicted tags: ['DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'NOUN', 'CONJ', 'VERB', 'VERB', 'ADP', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN']\n",
      "Actual tags:    ('DET', 'NOUN', 'VERB', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'CONJ', 'VERB', 'NUM', 'ADP', 'NUM', 'ADJ', 'NOUN', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN')\n",
      "Sentence: debenture holders are expected to convert most of the debentures into common because the value of the stock received in a conversion would exceed the 1,103.11 redemption price\n",
      "Predicted tags: ['NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NOUN', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'DET', 'NUM', 'NOUN', 'NOUN')\n",
      "Sentence: commodore international ltd. said it will report a loss for the first quarter ended sept. 30 because sales of personal computers for the home market remained weak in some major countries\n",
      "Predicted tags: ['NOUN', 'NOUN', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'NUM', 'ADP', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'ADJ', 'ADP', 'DET', 'ADJ', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'NOUN', 'NOUN', 'VERB', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'NOUN', 'NUM', 'ADP', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'ADJ', 'ADP', 'DET', 'ADJ', 'NOUN')\n",
      "Sentence: that will mark the second consecutive quarterly loss for commodore and will raise additional questions about whether it can sustain the turnaround it had seemed to be engineering\n",
      "Predicted tags: ['DET', 'VERB', 'VERB', 'DET', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'VERB', 'VERB', 'ADJ', 'NOUN', 'ADP', 'ADP', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'NOUN']\n",
      "Actual tags:    ('DET', 'VERB', 'VERB', 'DET', 'ADJ', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'VERB', 'VERB', 'ADJ', 'NOUN', 'ADP', 'ADP', 'PRON', 'VERB', 'VERB', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'NOUN')\n",
      "Conll2000 Corpus Accuracy: 0.9356\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences_conll2000 = conll2000.tagged_sents(tagset='universal')\n",
    "misclassification_count = train_and_evaluate('Conll2000', tagged_sentences_conll2000, misclassification_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: large banks -- those with assets of one billion dlrs or more -- reporting fourth-quarter losses totaled 22 the fdic said\n",
      "Predicted tags: ['ADJ', 'NOUN', '.', 'DET', 'ADP', 'NOUN', 'ADP', 'NUM', 'NUM', 'NOUN', 'CONJ', 'ADJ', '.', 'VERB', 'ADJ', 'NOUN', 'VERB', 'NUM', 'DET', 'NOUN', 'VERB']\n",
      "Actual tags:    ('ADJ', 'NOUN', '.', 'DET', 'ADP', 'NOUN', 'ADP', 'NUM', 'NUM', 'NOUN', 'CONJ', 'ADJ', '.', 'VERB', 'ADJ', 'NOUN', 'VERB', 'NUM', 'DET', 'NOUN', 'VERB')\n",
      "Sentence: seidman said it was too early to say what effect brazil's moratorium on debt interest payments would have on u.s. banks\n",
      "Predicted tags: ['NOUN', 'VERB', 'PRON', 'VERB', 'ADV', 'ADJ', 'PRT', 'VERB', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'ADP', 'NOUN', 'NOUN']\n",
      "Actual tags:    ('NOUN', 'VERB', 'PRON', 'VERB', 'ADV', 'ADJ', 'PRT', 'VERB', 'PRON', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'VERB', 'VERB', 'ADP', 'NOUN', 'NOUN')\n",
      "Sentence: he said bank deregulation had given managers more freedom to run their banks and that an increase in failures was to be expected\n",
      "Predicted tags: ['PRON', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'NOUN', 'ADJ', 'NOUN', 'PRT', 'VERB', 'PRON', 'NOUN', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'VERB', 'PRT', 'VERB', 'VERB']\n",
      "Actual tags:    ('PRON', 'VERB', 'NOUN', 'NOUN', 'VERB', 'VERB', 'NOUN', 'ADV', 'NOUN', 'PRT', 'VERB', 'PRON', 'NOUN', 'CONJ', 'DET', 'DET', 'NOUN', 'ADP', 'NOUN', 'VERB', 'PRT', 'VERB', 'VERB')\n",
      "Sentence: but this freedom from regulatory restraints also has meant other banks that were better managed have gotten stronger seidman said\n",
      "Predicted tags: ['CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADV', 'VERB', 'VERB', 'ADJ', 'NOUN', 'ADP', 'VERB', 'ADV', 'VERB', 'VERB', 'VERB', 'ADJ', 'NOUN', 'VERB']\n",
      "Actual tags:    ('CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADV', 'VERB', 'VERB', 'ADJ', 'NOUN', 'DET', 'VERB', 'ADJ', 'VERB', 'VERB', 'VERB', 'ADJ', 'NOUN', 'VERB')\n",
      "Sentence: somerset savings bank lt sosa 4th qtr feb 28 net shr 55 cts vs na net 2,512,000 vs 773,000 year net 7,123,000 vs 3,098,000 assets 417.7 mln vs 251.1 mln deposits 329.4 mln vs 230.1 mln loans net 366.1 mln vs 205.2 mln note some per shr amounts not available as company converted to public ownership in july 1986\n",
      "Predicted tags: ['NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NUM', 'ADJ', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'ADV', 'ADJ', 'ADP', 'NOUN', 'VERB', 'PRT', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'NUM']\n",
      "Actual tags:    ('NOUN', 'NOUN', 'NOUN', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'ADJ', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NUM', 'ADJ', 'ADJ', 'NUM', 'NOUN', 'NUM', 'NOUN', 'NUM', 'NOUN', 'ADV', 'NUM', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'ADV', 'NUM', 'NOUN', 'NOUN', 'NOUN', 'NUM', 'NOUN', 'NOUN', 'NUM', 'ADJ', 'NOUN', 'DET', 'ADP', 'NOUN', 'NOUN', 'ADV', 'ADJ', 'ADP', 'NOUN', 'VERB', 'PRT', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'NUM')\n",
      "Reuters Corpus Accuracy: 0.9262\n"
     ]
    }
   ],
   "source": [
    "reuters_files = reuters.fileids()\n",
    "\n",
    "# Tokenize the raw text into sentences and apply POS tagging\n",
    "tagged_sentences_reuters = []\n",
    "for file_id in reuters_files:\n",
    "    raw_text = reuters.raw(file_id)\n",
    "    sentences = sent_tokenize(raw_text)\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        tagged_sentence = pos_tag(words, tagset='universal')\n",
    "        tagged_sentences_reuters.append(tagged_sentence)\n",
    "        \n",
    "misclassification_count =train_and_evaluate('Reuters', tagged_sentences_reuters, misclassification_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Observe the most misclassification elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mispredictions(misclassification_count):\n",
    "    misclassification_list = []\n",
    "    new_sorted_dict = defaultdict(Counter)\n",
    "    for gold_tag, predictions in misclassification_count.items():\n",
    "        for predicted_tag, count in predictions.items():\n",
    "            misclassification_list.append((gold_tag, predicted_tag, count))\n",
    "    \n",
    "    # Sort the list by count in descending order and take the top 5\n",
    "    misclassification_list = sorted(misclassification_list, key=lambda x: x[2], reverse=True)[:5]\n",
    "    \n",
    "    for gold_tag, predicted_tag, count in misclassification_list:\n",
    "        print(f\"Gold Tag: {gold_tag}, Predicted Tag: {predicted_tag}, Count: {count}\")\n",
    "        new_sorted_dict[gold_tag][predicted_tag] = count\n",
    "    \n",
    "    return new_sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold Tag: NOUN, Predicted Tag: ADJ, Count: 4428\n",
      "Gold Tag: ADJ, Predicted Tag: NOUN, Count: 4208\n",
      "Gold Tag: NOUN, Predicted Tag: VERB, Count: 3919\n",
      "Gold Tag: VERB, Predicted Tag: NOUN, Count: 3383\n",
      "Gold Tag: NUM, Predicted Tag: NOUN, Count: 1962\n"
     ]
    }
   ],
   "source": [
    "new_dict = print_mispredictions(misclassification_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
